{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from os.path import join as pjoin\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class_map = {'0':'Button', '1':'CheckBox', '2':'Chronometer', '3':'EditText', '4':'ImageButton', '5':'ImageView',\n",
    "               '6':'ProgressBar', '7':'RadioButton', '8':'RatingBar', '9':'SeekBar', '10':'Spinner', '11':'Switch',\n",
    "               '12':'ToggleButton', '13':'VideoView', '14':'TextView'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipping(org, bbox, write_path=None, show=False, padding=(30, 20)):\n",
    "    (column_min, row_min, column_max, row_max) = bbox\n",
    "    column_min = max(column_min - padding[0], 0)\n",
    "    column_max = min(column_max + padding[0], org.shape[1])\n",
    "    row_min = max(row_min - padding[1], 0)\n",
    "    row_max = min(row_max + padding[1], org.shape[0])\n",
    "    clip = org[row_min:row_max, column_min:column_max]\n",
    "    if show:\n",
    "        cv2.imshow('clipping', clip)\n",
    "        cv2.waitKey()\n",
    "    if write_path is not None:\n",
    "        cv2.imwrite(write_path, clip)\n",
    "    return clip\n",
    "\n",
    "\n",
    "def resize_label(bboxes, d_height, gt_height, bias=0):\n",
    "    bboxes_new = []\n",
    "    scale = gt_height / d_height\n",
    "    for bbox in bboxes:\n",
    "        bbox = [int(b * scale + bias) for b in bbox]\n",
    "        bboxes_new.append(bbox)\n",
    "    return bboxes_new\n",
    "\n",
    "\n",
    "def draw_bounding_box(org, corners, color=(0, 255, 0), line=2, show=False):\n",
    "    board = org.copy()\n",
    "    for i in range(len(corners)):\n",
    "        board = cv2.rectangle(board, (corners[i][0], corners[i][1]), (corners[i][2], corners[i][3]), color, line)\n",
    "    if show:\n",
    "        cv2.imshow('a', cv2.resize(board, (500, 1000)))\n",
    "        cv2.waitKey(0)\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_detect_result_json(reslut_file_root, shrink=0):\n",
    "    def is_bottom_or_top(corner):\n",
    "        column_min, row_min, column_max, row_max = corner\n",
    "        if row_max < 36 or row_min > 725:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    result_files = glob(pjoin(reslut_file_root, '*.json'))\n",
    "    compos_reform = {}\n",
    "    print('Loading %d detection results' % len(result_files))\n",
    "    for reslut_file in tqdm(result_files[:]):\n",
    "        img_name = reslut_file.split('\\\\')[-1].split('.')[0]\n",
    "        compos = json.load(open(reslut_file, 'r'))['compos']\n",
    "        for compo in compos:\n",
    "            if compo['column_max'] - compo['column_min'] < 10 or compo['row_max'] - compo['row_min'] < 10:\n",
    "                continue\n",
    "            if is_bottom_or_top((compo['column_min'], compo['row_min'], compo['column_max'], compo['row_max'])):\n",
    "                continue\n",
    "            if img_name not in compos_reform:\n",
    "                compos_reform[img_name] = {'bboxes': [[compo['column_min'] + shrink, compo['row_min'] + shrink, compo['column_max'] - shrink, compo['row_max'] - shrink]],\n",
    "                                           'categories': [compo['category']]}\n",
    "            else:\n",
    "                compos_reform[img_name]['bboxes'].append([compo['column_min'] + shrink, compo['row_min'] + shrink, compo['column_max'] - shrink, compo['row_max'] - shrink])\n",
    "                compos_reform[img_name]['categories'].append(compo['category'])\n",
    "    return compos_reform\n",
    "\n",
    "\n",
    "def load_ground_truth_json(gt_file):\n",
    "    def get_img_by_id(img_id):\n",
    "        for image in images:\n",
    "            if image['id'] == img_id:\n",
    "                return image['file_name'].split('/')[-1][:-4], (image['height'], image['width'])\n",
    "\n",
    "    def cvt_bbox(bbox):\n",
    "        '''\n",
    "        :param bbox: [x,y,width,height]\n",
    "        :return: [col_min, row_min, col_max, row_max]\n",
    "        '''\n",
    "        bbox = [int(b) for b in bbox]\n",
    "        return [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
    "\n",
    "    data = json.load(open(gt_file, 'r'))\n",
    "    images = data['images']\n",
    "    annots = data['annotations']\n",
    "    compos = {}\n",
    "    print('Loading %d ground truth' % len(annots))\n",
    "    for annot in tqdm(annots):\n",
    "        img_name, size = get_img_by_id(annot['image_id'])\n",
    "        if img_name not in compos:\n",
    "            compos[img_name] = {'bboxes': [cvt_bbox(annot['bbox'])], 'categories': [class_map[str(annot['category_id'])]], 'size': size}\n",
    "        else:\n",
    "            compos[img_name]['bboxes'].append(cvt_bbox(annot['bbox']))\n",
    "            compos[img_name]['categories'].append(class_map[str(annot['category_id'])])\n",
    "    return compos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                              | 11/4708 [00:00<00:45, 102.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4708 detection results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4708/4708 [00:05<00:00, 822.68it/s]\n",
      "  8%|██████▏                                                                   | 7194/86646 [00:00<00:01, 71672.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 86646 ground truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████▎                 | 65931/86646 [00:07<00:06, 3325.28it/s]"
     ]
    }
   ],
   "source": [
    "detect = load_detect_result_json('E:\\\\Mulong\\\\Result\\\\rico\\\\rico_uied\\\\rico_new_uied_cls\\\\merge')\n",
    "gt = load_ground_truth_json('E:\\\\Mulong\\\\Datasets\\\\rico\\\\instances_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(detection, ground_truth, img_root, cnn, show=False):\n",
    "\n",
    "    store_gt_categories = []\n",
    "    store_det_clips = []\n",
    "\n",
    "    def match(org, d_bbox, gt_compos, matched):\n",
    "        '''\n",
    "        :param matched: mark if the ground truth component is matched\n",
    "        :param d_bbox: [col_min, row_min, col_max, row_max]\n",
    "        :param gt_bboxes: list of ground truth [[col_min, row_min, col_max, row_max]]\n",
    "        :return: Boolean: if IOU large enough or detected box is contained by ground truth\n",
    "        '''\n",
    "        area_d = (d_bbox[2] - d_bbox[0]) * (d_bbox[3] - d_bbox[1])\n",
    "        gt_bboxes = gt_compos['bboxes']\n",
    "        gt_categories = gt_compos['categories']\n",
    "        for i, gt_bbox in enumerate(gt_bboxes):\n",
    "            if matched[i] == 0:\n",
    "                continue\n",
    "            area_gt = (gt_bbox[2] - gt_bbox[0]) * (gt_bbox[3] - gt_bbox[1])\n",
    "            col_min = max(d_bbox[0], gt_bbox[0])\n",
    "            row_min = max(d_bbox[1], gt_bbox[1])\n",
    "            col_max = min(d_bbox[2], gt_bbox[2])\n",
    "            row_max = min(d_bbox[3], gt_bbox[3])\n",
    "            # if not intersected, area intersection should be 0\n",
    "            w = max(0, col_max - col_min)\n",
    "            h = max(0, row_max - row_min)\n",
    "            area_inter = w * h\n",
    "            if area_inter == 0:\n",
    "                continue\n",
    "            iod = area_inter / area_d\n",
    "            iou = area_inter / (area_d + area_gt - area_inter)\n",
    "            if iou > 0.9 or iod == 1:\n",
    "                matched[i] = 0\n",
    "                store_gt_categories.append(gt_categories[i])\n",
    "                store_det_clips.append(clipping(org, d_bbox, show=show))\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    amount = len(detection)\n",
    "    FP, FN = 0, 0\n",
    "    for i, image_id in enumerate(detection):\n",
    "        img = cv2.imread(pjoin(img_root, image_id + '.jpg'))\n",
    "        d_compos = detection[image_id]\n",
    "        if image_id not in ground_truth:\n",
    "            continue\n",
    "        gt_compos = ground_truth[image_id]\n",
    "        org_height = gt_compos['size'][0]\n",
    "\n",
    "        d_compos['bboxes'] = resize_label(d_compos['bboxes'], 800, org_height)\n",
    "        matched = np.ones(len(gt_compos['bboxes']), dtype=int)\n",
    "        for d_bbox in d_compos['bboxes']:\n",
    "            if not match(img, d_bbox, gt_compos, matched):\n",
    "                FP += 1\n",
    "        FN += sum(matched)\n",
    "        \n",
    "        print(\"[%d/%d]\" %(i, amount))\n",
    "        if i > 1000:\n",
    "            break\n",
    "\n",
    "    return store_det_clips, store_gt_categories, (FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded From E:/Mulong/Model/rico_compos/cnn-rico-1.h5\n"
     ]
    }
   ],
   "source": [
    "from CNN import CNN\n",
    "cnn = CNN('E:/Mulong/Model/rico_compos/cnn-rico-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/4706]\n",
      "[1/4706]\n",
      "[2/4706]\n",
      "[3/4706]\n",
      "[4/4706]\n",
      "[5/4706]\n",
      "[6/4706]\n",
      "[7/4706]\n",
      "[8/4706]\n",
      "[9/4706]\n",
      "[10/4706]\n",
      "[11/4706]\n",
      "[12/4706]\n",
      "[13/4706]\n",
      "[14/4706]\n",
      "[15/4706]\n",
      "[16/4706]\n",
      "[17/4706]\n",
      "[18/4706]\n",
      "[19/4706]\n",
      "[20/4706]\n",
      "[21/4706]\n",
      "[22/4706]\n",
      "[23/4706]\n",
      "[24/4706]\n",
      "[25/4706]\n",
      "[26/4706]\n",
      "[27/4706]\n",
      "[28/4706]\n",
      "[29/4706]\n",
      "[30/4706]\n",
      "[31/4706]\n",
      "[32/4706]\n",
      "[33/4706]\n",
      "[34/4706]\n",
      "[35/4706]\n",
      "[36/4706]\n",
      "[37/4706]\n",
      "[38/4706]\n",
      "[39/4706]\n",
      "[40/4706]\n",
      "[41/4706]\n",
      "[42/4706]\n",
      "[43/4706]\n",
      "[44/4706]\n",
      "[45/4706]\n",
      "[46/4706]\n",
      "[47/4706]\n",
      "[48/4706]\n",
      "[49/4706]\n",
      "[50/4706]\n",
      "[51/4706]\n",
      "[52/4706]\n",
      "[53/4706]\n",
      "[54/4706]\n",
      "[55/4706]\n",
      "[56/4706]\n",
      "[57/4706]\n",
      "[58/4706]\n",
      "[59/4706]\n",
      "[60/4706]\n",
      "[61/4706]\n",
      "[62/4706]\n",
      "[63/4706]\n",
      "[64/4706]\n",
      "[65/4706]\n",
      "[66/4706]\n",
      "[67/4706]\n",
      "[68/4706]\n",
      "[69/4706]\n",
      "[70/4706]\n",
      "[71/4706]\n",
      "[72/4706]\n",
      "[73/4706]\n",
      "[74/4706]\n",
      "[75/4706]\n",
      "[76/4706]\n",
      "[77/4706]\n",
      "[78/4706]\n",
      "[79/4706]\n",
      "[80/4706]\n",
      "[81/4706]\n",
      "[82/4706]\n",
      "[83/4706]\n",
      "[84/4706]\n",
      "[85/4706]\n",
      "[86/4706]\n",
      "[87/4706]\n",
      "[88/4706]\n",
      "[89/4706]\n",
      "[90/4706]\n",
      "[91/4706]\n",
      "[92/4706]\n",
      "[93/4706]\n",
      "[94/4706]\n",
      "[95/4706]\n",
      "[96/4706]\n",
      "[97/4706]\n",
      "[98/4706]\n",
      "[99/4706]\n",
      "[100/4706]\n",
      "[101/4706]\n",
      "[102/4706]\n",
      "[103/4706]\n",
      "[104/4706]\n",
      "[105/4706]\n",
      "[106/4706]\n",
      "[107/4706]\n",
      "[108/4706]\n",
      "[109/4706]\n",
      "[110/4706]\n",
      "[111/4706]\n",
      "[112/4706]\n",
      "[113/4706]\n",
      "[114/4706]\n",
      "[115/4706]\n",
      "[116/4706]\n",
      "[117/4706]\n",
      "[118/4706]\n",
      "[119/4706]\n",
      "[120/4706]\n",
      "[121/4706]\n",
      "[122/4706]\n",
      "[123/4706]\n",
      "[124/4706]\n",
      "[125/4706]\n",
      "[126/4706]\n",
      "[127/4706]\n",
      "[128/4706]\n",
      "[129/4706]\n",
      "[130/4706]\n",
      "[131/4706]\n",
      "[132/4706]\n",
      "[133/4706]\n",
      "[134/4706]\n",
      "[135/4706]\n",
      "[136/4706]\n",
      "[137/4706]\n",
      "[138/4706]\n",
      "[139/4706]\n",
      "[140/4706]\n",
      "[141/4706]\n",
      "[142/4706]\n",
      "[143/4706]\n",
      "[144/4706]\n",
      "[145/4706]\n",
      "[146/4706]\n",
      "[147/4706]\n",
      "[148/4706]\n",
      "[149/4706]\n",
      "[150/4706]\n",
      "[151/4706]\n",
      "[152/4706]\n",
      "[153/4706]\n",
      "[154/4706]\n",
      "[155/4706]\n",
      "[156/4706]\n",
      "[157/4706]\n",
      "[158/4706]\n",
      "[159/4706]\n",
      "[160/4706]\n",
      "[161/4706]\n",
      "[162/4706]\n",
      "[163/4706]\n",
      "[164/4706]\n",
      "[165/4706]\n",
      "[166/4706]\n",
      "[167/4706]\n",
      "[168/4706]\n",
      "[169/4706]\n",
      "[170/4706]\n",
      "[171/4706]\n",
      "[172/4706]\n",
      "[173/4706]\n",
      "[174/4706]\n",
      "[175/4706]\n",
      "[176/4706]\n",
      "[177/4706]\n",
      "[178/4706]\n",
      "[179/4706]\n",
      "[180/4706]\n",
      "[181/4706]\n",
      "[182/4706]\n",
      "[183/4706]\n",
      "[184/4706]\n",
      "[185/4706]\n",
      "[186/4706]\n",
      "[187/4706]\n",
      "[188/4706]\n",
      "[189/4706]\n",
      "[190/4706]\n",
      "[191/4706]\n",
      "[192/4706]\n",
      "[193/4706]\n",
      "[194/4706]\n",
      "[195/4706]\n",
      "[196/4706]\n",
      "[197/4706]\n",
      "[198/4706]\n",
      "[199/4706]\n",
      "[200/4706]\n",
      "[201/4706]\n",
      "[202/4706]\n",
      "[203/4706]\n",
      "[204/4706]\n",
      "[205/4706]\n",
      "[206/4706]\n",
      "[207/4706]\n",
      "[208/4706]\n",
      "[209/4706]\n",
      "[210/4706]\n",
      "[211/4706]\n",
      "[212/4706]\n",
      "[213/4706]\n",
      "[214/4706]\n",
      "[215/4706]\n",
      "[216/4706]\n",
      "[217/4706]\n",
      "[218/4706]\n",
      "[219/4706]\n",
      "[220/4706]\n",
      "[221/4706]\n",
      "[222/4706]\n",
      "[223/4706]\n",
      "[224/4706]\n",
      "[225/4706]\n",
      "[226/4706]\n",
      "[227/4706]\n",
      "[228/4706]\n",
      "[229/4706]\n",
      "[230/4706]\n",
      "[231/4706]\n",
      "[232/4706]\n",
      "[233/4706]\n",
      "[234/4706]\n",
      "[235/4706]\n",
      "[236/4706]\n",
      "[237/4706]\n",
      "[238/4706]\n",
      "[239/4706]\n",
      "[240/4706]\n",
      "[241/4706]\n",
      "[242/4706]\n",
      "[243/4706]\n",
      "[244/4706]\n",
      "[245/4706]\n",
      "[246/4706]\n",
      "[247/4706]\n",
      "[248/4706]\n",
      "[249/4706]\n",
      "[250/4706]\n",
      "[251/4706]\n",
      "[252/4706]\n",
      "[253/4706]\n",
      "[254/4706]\n",
      "[255/4706]\n",
      "[256/4706]\n",
      "[257/4706]\n",
      "[258/4706]\n",
      "[259/4706]\n",
      "[260/4706]\n",
      "[261/4706]\n",
      "[262/4706]\n",
      "[263/4706]\n",
      "[264/4706]\n",
      "[265/4706]\n",
      "[266/4706]\n",
      "[267/4706]\n",
      "[268/4706]\n",
      "[269/4706]\n",
      "[270/4706]\n",
      "[271/4706]\n",
      "[272/4706]\n",
      "[273/4706]\n",
      "[274/4706]\n",
      "[275/4706]\n",
      "[276/4706]\n",
      "[277/4706]\n",
      "[278/4706]\n",
      "[279/4706]\n",
      "[280/4706]\n",
      "[281/4706]\n",
      "[282/4706]\n",
      "[283/4706]\n",
      "[284/4706]\n",
      "[285/4706]\n",
      "[286/4706]\n",
      "[287/4706]\n",
      "[288/4706]\n",
      "[289/4706]\n",
      "[290/4706]\n",
      "[291/4706]\n",
      "[292/4706]\n",
      "[293/4706]\n",
      "[294/4706]\n",
      "[295/4706]\n",
      "[296/4706]\n",
      "[297/4706]\n",
      "[298/4706]\n",
      "[299/4706]\n",
      "[300/4706]\n",
      "[301/4706]\n",
      "[302/4706]\n",
      "[303/4706]\n",
      "[304/4706]\n",
      "[305/4706]\n",
      "[306/4706]\n",
      "[307/4706]\n",
      "[308/4706]\n",
      "[309/4706]\n",
      "[310/4706]\n",
      "[311/4706]\n",
      "[312/4706]\n",
      "[313/4706]\n",
      "[314/4706]\n",
      "[315/4706]\n",
      "[316/4706]\n",
      "[317/4706]\n",
      "[318/4706]\n",
      "[319/4706]\n",
      "[320/4706]\n",
      "[321/4706]\n",
      "[322/4706]\n",
      "[323/4706]\n",
      "[324/4706]\n",
      "[325/4706]\n",
      "[326/4706]\n",
      "[327/4706]\n",
      "[328/4706]\n",
      "[329/4706]\n",
      "[330/4706]\n",
      "[331/4706]\n",
      "[332/4706]\n",
      "[333/4706]\n",
      "[334/4706]\n",
      "[335/4706]\n",
      "[336/4706]\n",
      "[337/4706]\n",
      "[338/4706]\n",
      "[339/4706]\n",
      "[340/4706]\n",
      "[341/4706]\n",
      "[342/4706]\n",
      "[343/4706]\n",
      "[344/4706]\n",
      "[345/4706]\n",
      "[346/4706]\n",
      "[347/4706]\n",
      "[348/4706]\n",
      "[349/4706]\n",
      "[350/4706]\n",
      "[351/4706]\n",
      "[352/4706]\n",
      "[353/4706]\n",
      "[354/4706]\n",
      "[355/4706]\n",
      "[356/4706]\n",
      "[357/4706]\n",
      "[358/4706]\n",
      "[359/4706]\n",
      "[360/4706]\n",
      "[361/4706]\n",
      "[362/4706]\n",
      "[363/4706]\n",
      "[364/4706]\n",
      "[365/4706]\n",
      "[366/4706]\n",
      "[367/4706]\n",
      "[368/4706]\n",
      "[369/4706]\n",
      "[370/4706]\n",
      "[371/4706]\n",
      "[372/4706]\n",
      "[373/4706]\n",
      "[374/4706]\n",
      "[375/4706]\n",
      "[376/4706]\n",
      "[377/4706]\n",
      "[378/4706]\n",
      "[379/4706]\n",
      "[380/4706]\n",
      "[381/4706]\n",
      "[382/4706]\n",
      "[383/4706]\n",
      "[384/4706]\n",
      "[385/4706]\n",
      "[386/4706]\n",
      "[387/4706]\n",
      "[388/4706]\n",
      "[389/4706]\n",
      "[390/4706]\n",
      "[391/4706]\n",
      "[392/4706]\n",
      "[393/4706]\n",
      "[394/4706]\n",
      "[395/4706]\n",
      "[396/4706]\n",
      "[397/4706]\n",
      "[398/4706]\n",
      "[399/4706]\n",
      "[400/4706]\n",
      "[401/4706]\n",
      "[402/4706]\n",
      "[403/4706]\n",
      "[404/4706]\n",
      "[405/4706]\n",
      "[406/4706]\n",
      "[407/4706]\n",
      "[408/4706]\n",
      "[409/4706]\n",
      "[410/4706]\n",
      "[411/4706]\n",
      "[412/4706]\n",
      "[413/4706]\n",
      "[414/4706]\n",
      "[415/4706]\n",
      "[416/4706]\n",
      "[417/4706]\n",
      "[418/4706]\n",
      "[419/4706]\n",
      "[420/4706]\n",
      "[421/4706]\n",
      "[422/4706]\n",
      "[423/4706]\n",
      "[424/4706]\n",
      "[425/4706]\n",
      "[426/4706]\n",
      "[427/4706]\n",
      "[428/4706]\n",
      "[429/4706]\n",
      "[430/4706]\n",
      "[431/4706]\n",
      "[432/4706]\n",
      "[433/4706]\n",
      "[434/4706]\n",
      "[435/4706]\n",
      "[436/4706]\n",
      "[437/4706]\n",
      "[438/4706]\n",
      "[439/4706]\n",
      "[440/4706]\n",
      "[441/4706]\n",
      "[442/4706]\n",
      "[443/4706]\n",
      "[444/4706]\n",
      "[445/4706]\n",
      "[446/4706]\n",
      "[447/4706]\n",
      "[448/4706]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4:Insufficient memory) Failed to allocate 6220800 bytes in function 'cv::OutOfMemoryError'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-47306ad23efb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdet_clips\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mFP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'E:\\\\Mulong\\\\Datasets\\\\rico\\\\combined'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-066d52ae0017>\u001b[0m in \u001b[0;36meval\u001b[1;34m(detection, ground_truth, img_root, cnn, show)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mFP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0md_compos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4:Insufficient memory) Failed to allocate 6220800 bytes in function 'cv::OutOfMemoryError'\n"
     ]
    }
   ],
   "source": [
    "det_clips, gt_labels, (FP, FN) = eval(detect, gt, 'E:\\\\Mulong\\\\Datasets\\\\rico\\\\combined', cnn, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TextView',\n",
       " 'ImageButton',\n",
       " 'ImageButton',\n",
       " 'TextView',\n",
       " 'ImageView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'ImageButton',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'ImageView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'EditText',\n",
       " 'TextView',\n",
       " 'EditText',\n",
       " 'EditText',\n",
       " 'TextView',\n",
       " 'Button',\n",
       " 'Button',\n",
       " 'Button',\n",
       " 'Button',\n",
       " 'Button',\n",
       " 'ImageView',\n",
       " 'ImageView',\n",
       " 'TextView',\n",
       " 'ImageView',\n",
       " 'TextView',\n",
       " 'ImageView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'ImageButton',\n",
       " 'TextView',\n",
       " 'ImageButton',\n",
       " 'TextView',\n",
       " 'CheckBox',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'ImageButton',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'ImageView',\n",
       " 'Button',\n",
       " 'ImageButton',\n",
       " 'TextView',\n",
       " 'ImageButton',\n",
       " 'ImageButton',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'Button',\n",
       " 'Button',\n",
       " 'Button',\n",
       " 'TextView',\n",
       " 'ImageView',\n",
       " 'TextView',\n",
       " 'TextView',\n",
       " 'ImageView',\n",
       " 'TextView']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(det_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.predict(det_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
